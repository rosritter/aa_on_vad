{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/timur.bikbulatov/personal/aa_on_vad\n",
      "/home/timur.bikbulatov/personal/aa_on_vad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timur.bikbulatov/miniconda3/envs/aaml/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from functools import partial\n",
    "play = partial(IPython.display.Audio,\n",
    "               rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def plot(y:list):\n",
    "    trace = []\n",
    "    colors = [\n",
    "        'Blue',\n",
    "        'Orange',\n",
    "        'Green',\n",
    "        'Red',\n",
    "        'Purple',\n",
    "        'Magenta',\n",
    "        'Cyan',\n",
    "        'Brown',\n",
    "        'Pink',\n",
    "        'Lime',\n",
    "        'Yellow',\n",
    "        'Teal',\n",
    "        'Olive',\n",
    "        'Navy',\n",
    "        'Maroon',\n",
    "        'Coral',\n",
    "        'Gold',\n",
    "        'Indigo',\n",
    "        'Turquoise',\n",
    "        'Lavender',\n",
    "        'Mint',\n",
    "        'Silver',\n",
    "        ]\n",
    "    for ik, y_ in enumerate(y):\n",
    "        trace.append(go.Scatter(x=np.arange(len(y_)), y=y_, mode='lines', name=f'arg # {ik + 1}', line=dict(color=colors[ik])))\n",
    "\n",
    "    # Combining both traces into one figure\n",
    "    fig = go.Figure(data=trace)\n",
    "\n",
    "    # Setting the layout\n",
    "    fig.update_layout(\n",
    "        title='Two Line Charts on One Plot',\n",
    "        xaxis_title='X-axis',\n",
    "        yaxis_title='Y-axis',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    # Display the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.librispeech import get_librispeech_example, LibriSpeechWrapper\n",
    "from src.datasets.urbansound import UrbanSoundDataset, read_arrf\n",
    "from src.datasets.musan import MusanMusicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_datasets = [\n",
    "    LibriSpeechWrapper(get_librispeech_example(), erase_silence=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_datasets = [\n",
    "    MusanMusicDataset(\n",
    "    root_dir='datasets/musan/music',\n",
    "    target_sample_rate=16000,\n",
    "    segment_length=None\n",
    "    ),\n",
    "    UrbanSoundDataset(read_arrf())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional, Union, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LengthConfig:\n",
    "    \"\"\"Configuration for output audio length\"\"\"\n",
    "    min_length: float  # in seconds\n",
    "    max_length: float  # in seconds\n",
    "    \n",
    "    def get_length_samples(self, sample_rate: int, random_state: Optional[np.random.RandomState] = None) -> int:\n",
    "        \"\"\"Get random length in samples within configured range\"\"\"\n",
    "        min_samples = int(self.min_length * sample_rate)\n",
    "        max_samples = int(self.max_length * sample_rate)\n",
    "        if random_state is not None:\n",
    "            return random_state.randint(min_samples, max_samples + 1)\n",
    "        return random.randint(min_samples, max_samples)\n",
    "\n",
    "class VADMixedDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        speech_datasets: List[Dataset],\n",
    "        noise_datasets: List[Dataset],\n",
    "        sample_rate: int = 16000,\n",
    "        length_config: Optional[LengthConfig] = None,\n",
    "        fixed_length: Optional[float] = None,  # in seconds\n",
    "        target_speech_ratio: float = 0.3,  # target ratio of speech in generated audio\n",
    "        speech_ratio_tolerance: float = 0.05,  # allowed deviation from target ratio\n",
    "        speech_prob_weights: Optional[List[float]] = None,  # weights for each speech dataset\n",
    "        noise_prob_weights: Optional[List[float]] = None,  # weights for each noise dataset\n",
    "        min_speech_length: float = 0.2,  # minimum speech segment length in seconds\n",
    "        deterministic: bool = False,  # whether to generate same samples each time\n",
    "        seed: int = 42,  # seed for deterministic mode\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the VAD mixed dataset.\n",
    "        \n",
    "        Args:\n",
    "            speech_datasets: List of datasets containing speech samples\n",
    "            noise_datasets: List of datasets containing non-speech samples\n",
    "            sample_rate: Audio sample rate\n",
    "            length_config: Configuration for random length range (if not using fixed_length)\n",
    "            fixed_length: Fixed length for all outputs (in seconds, if not using length_config)\n",
    "            target_speech_ratio: Target ratio of speech presence in generated audio (0.0 to 1.0)\n",
    "            speech_ratio_tolerance: Allowed deviation from target speech ratio\n",
    "            speech_prob_weights: Optional weights for sampling from speech datasets\n",
    "            noise_prob_weights: Optional weights for sampling from noise datasets\n",
    "            min_speech_length: Minimum length for individual speech segments\n",
    "            deterministic: If True, will generate same samples each time for same index\n",
    "            seed: Random seed for deterministic mode\n",
    "        \"\"\"\n",
    "        if length_config is not None and fixed_length is not None:\n",
    "            raise ValueError(\"Cannot specify both length_config and fixed_length\")\n",
    "        elif length_config is None and fixed_length is None:\n",
    "            self.length_config = None\n",
    "            self.fixed_length = 3.0\n",
    "        else:\n",
    "            self.length_config = length_config\n",
    "            self.fixed_length = fixed_length\n",
    "        \n",
    "        self.speech_datasets = speech_datasets\n",
    "        self.noise_datasets = noise_datasets\n",
    "        self.sample_rate = sample_rate\n",
    "        self.target_speech_ratio = target_speech_ratio\n",
    "        self.speech_ratio_tolerance = speech_ratio_tolerance\n",
    "        self.min_speech_length = int(min_speech_length * sample_rate)\n",
    "        self.deterministic = deterministic\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Set default uniform weights\n",
    "        if speech_prob_weights is None:\n",
    "            self.speech_prob_weights = [1.0 / len(speech_datasets)] * len(speech_datasets)\n",
    "        else:\n",
    "            total = sum(speech_prob_weights)\n",
    "            self.speech_prob_weights = [w / total for w in speech_prob_weights]\n",
    "        \n",
    "        if noise_prob_weights is None:\n",
    "            self.noise_prob_weights = [1.0 / len(noise_datasets)] * len(noise_datasets)\n",
    "        else:\n",
    "            total = sum(noise_prob_weights)\n",
    "            self.noise_prob_weights = [w / total for w in noise_prob_weights]\n",
    "        \n",
    "        # Store dataset lengths\n",
    "        self.speech_lengths = [len(dataset) for dataset in speech_datasets]\n",
    "        self.noise_lengths = [len(dataset) for dataset in noise_datasets]\n",
    "        self.length = sum(self.speech_lengths) + sum(self.noise_lengths)\n",
    "\n",
    "    def _get_random_generator(self, idx: int) -> Union[np.random.RandomState, None]:\n",
    "        \"\"\"Get random generator based on mode and index\"\"\"\n",
    "        if self.deterministic:\n",
    "            return np.random.RandomState(self.seed + idx)\n",
    "        return None\n",
    "\n",
    "    def _random_choice(self, \n",
    "                      options: List[int], \n",
    "                      weights: List[float], \n",
    "                      random_state: Optional[np.random.RandomState] = None) -> int:\n",
    "        \"\"\"Make a random choice with optional deterministic behavior\"\"\"\n",
    "        if random_state is not None:\n",
    "            return random_state.choice(options, p=weights)\n",
    "        return random.choices(options, weights=weights)[0]\n",
    "\n",
    "    def _random_int(self, \n",
    "                   low: int, \n",
    "                   high: int, \n",
    "                   random_state: Optional[np.random.RandomState] = None) -> int:\n",
    "        \"\"\"Get random integer with optional deterministic behavior\"\"\"\n",
    "        if random_state is not None:\n",
    "            return random_state.randint(low, high)\n",
    "        return random.randint(low, high - 1)\n",
    "\n",
    "    def _get_target_length(self, random_state: Optional[np.random.RandomState] = None) -> int:\n",
    "        \"\"\"Get target length in samples for current audio segment\"\"\"\n",
    "        if self.length_config is not None:\n",
    "            return self.length_config.get_length_samples(self.sample_rate, random_state)\n",
    "        else:\n",
    "            return int(self.fixed_length * self.sample_rate)\n",
    "\n",
    "    def _get_random_slice(self, \n",
    "                         audio: torch.Tensor, \n",
    "                         target_length: int,\n",
    "                         random_state: Optional[np.random.RandomState] = None) -> torch.Tensor:\n",
    "        \"\"\"Get a random slice of specified length from audio tensor\"\"\"\n",
    "        if audio.size(-1) <= target_length:\n",
    "            padding = target_length - audio.size(-1)\n",
    "            return F.pad(audio, (0, padding))\n",
    "        else:\n",
    "            start = self._random_int(0, audio.size(-1) - target_length + 1, random_state)\n",
    "            return audio[..., start:start + target_length]\n",
    "\n",
    "    def _get_audio_from_dataset(self, \n",
    "                              is_speech: bool,\n",
    "                              random_state: Optional[np.random.RandomState] = None) -> torch.Tensor:\n",
    "        \"\"\"Get a random audio sample from specified dataset type\"\"\"\n",
    "        datasets = self.speech_datasets if is_speech else self.noise_datasets\n",
    "        weights = self.speech_prob_weights if is_speech else self.noise_prob_weights\n",
    "        \n",
    "        dataset_idx = self._random_choice(\n",
    "            range(len(datasets)), \n",
    "            weights=weights,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        dataset = datasets[dataset_idx]\n",
    "        sample_idx = self._random_int(0, len(dataset), random_state)\n",
    "        return dataset[sample_idx]['sample']\n",
    "\n",
    "    def _calculate_current_speech_ratio(self, mask: torch.Tensor) -> float:\n",
    "        \"\"\"Calculate the current ratio of speech in the mask\"\"\"\n",
    "        return mask.mean().item()\n",
    "\n",
    "    def _generate_mixed_segment(self, \n",
    "                              target_length: int,\n",
    "                              random_state: Optional[np.random.RandomState] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generate a mixed audio segment with the target speech ratio\"\"\"\n",
    "        output = torch.zeros(target_length)\n",
    "        mask = torch.zeros(target_length)\n",
    "        available_positions = set(range(target_length))\n",
    "        current_ratio = 0.0\n",
    "\n",
    "        while (abs(current_ratio - self.target_speech_ratio) > self.speech_ratio_tolerance and \n",
    "               len(available_positions) >= self.min_speech_length):\n",
    "            \n",
    "            if current_ratio < self.target_speech_ratio:\n",
    "                # Need more speech\n",
    "                audio = self._get_audio_from_dataset(is_speech=True, random_state=random_state)\n",
    "                max_length = min(audio.size(-1), len(available_positions))\n",
    "                segment_length = self._random_int(self.min_speech_length, max_length + 1, random_state)\n",
    "            else:\n",
    "                # Need more noise\n",
    "                audio = self._get_audio_from_dataset(is_speech=False, random_state=random_state)\n",
    "                max_length = min(audio.size(-1), len(available_positions))\n",
    "                segment_length = self._random_int(self.min_speech_length, max_length + 1, random_state)\n",
    "\n",
    "            if len(available_positions) < segment_length:\n",
    "                break\n",
    "\n",
    "            # Find a continuous segment of available positions\n",
    "            available_list = sorted(list(available_positions))\n",
    "            start_idx = self._random_int(0, len(available_list) - segment_length + 1, random_state)\n",
    "            segment_positions = available_list[start_idx:start_idx + segment_length]\n",
    "            \n",
    "            # Update available positions\n",
    "            available_positions -= set(segment_positions)\n",
    "            \n",
    "            # Add audio segment\n",
    "            audio_segment = self._get_random_slice(audio, segment_length, random_state)\n",
    "            output[segment_positions] = audio_segment[:segment_length]\n",
    "            \n",
    "            # Update mask for speech segments\n",
    "            if current_ratio < self.target_speech_ratio:\n",
    "                mask[segment_positions] = 1.0\n",
    "            \n",
    "            current_ratio = self._calculate_current_speech_ratio(mask)\n",
    "\n",
    "        # Fill any remaining positions with noise\n",
    "        if available_positions:\n",
    "            noise = self._get_audio_from_dataset(is_speech=False, random_state=random_state)\n",
    "            remaining_positions = sorted(list(available_positions))\n",
    "            noise_segment = self._get_random_slice(noise, len(remaining_positions), random_state)\n",
    "            output[remaining_positions] = noise_segment\n",
    "\n",
    "        return output, mask\n",
    "\n",
    "    def _maybe_normalize_audio(self, audio: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Normalize audio to have max amplitude of 1\"\"\"\n",
    "        max_val = torch.abs(audio).max()\n",
    "        if max_val > 0:\n",
    "            return audio / max_val\n",
    "        return audio\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        # Get random generator based on mode\n",
    "        random_state = self._get_random_generator(idx)\n",
    "        \n",
    "        # Get target length for this sample\n",
    "        target_length = self._get_target_length(random_state)\n",
    "        \n",
    "        # Generate mixed segment with target speech ratio\n",
    "        mixed_audio, mask = self._generate_mixed_segment(target_length, random_state)\n",
    "        \n",
    "        # Normalize final audio\n",
    "        mixed_audio = self._maybe_normalize_audio(mixed_audio)\n",
    "        \n",
    "        return {\n",
    "            'sample': mixed_audio,\n",
    "            'mask': mask\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_dataset_fixed = VADMixedDataset(\n",
    "    speech_datasets=speech_datasets,\n",
    "    noise_datasets=noise_datasets,\n",
    "    sample_rate=16000,\n",
    "    fixed_length=6.0,\n",
    "    target_speech_ratio=0.3,\n",
    "    deterministic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_sample = vad_dataset_fixed[2]    # Will be exactly 6 seconds\n",
    "plot(list(fixed_sample.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(fixed_sample['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize datasets\\nspeech_datasets = [\\n    torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True),\\n    YourCustomSpeechDataset1(),\\n]\\n\\nnoise_datasets = [\\n    YourNoiseDataset1(),\\n    YourNoiseDataset2(),\\n]\\n\\n# Example 1: Fixed length output\\nvad_dataset_fixed = VADMixedDataset(\\n    speech_datasets=speech_datasets,\\n    noise_datasets=noise_datasets,\\n    sample_rate=16000,\\n    fixed_length=3.0,  # 3 seconds fixed length\\n    target_speech_ratio=0.3\\n)\\n\\n# Example 2: Random length output\\nlength_config = LengthConfig(min_length=2.0, max_length=5.0)  # Random between 2-5 seconds\\nvad_dataset_random = VADMixedDataset(\\n    speech_datasets=speech_datasets,\\n    noise_datasets=noise_datasets,\\n    sample_rate=16000,\\n    length_config=length_config,\\n    target_speech_ratio=0.3\\n)\\n\\n# Get samples\\nfixed_sample = vad_dataset_fixed[0]    # Will be exactly 3 seconds\\nrandom_sample = vad_dataset_random[0]  # Will be between 2-5 seconds\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "\"\"\"\n",
    "# Initialize datasets\n",
    "speech_datasets = [\n",
    "    torchaudio.datasets.LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True),\n",
    "    YourCustomSpeechDataset1(),\n",
    "]\n",
    "\n",
    "noise_datasets = [\n",
    "    YourNoiseDataset1(),\n",
    "    YourNoiseDataset2(),\n",
    "]\n",
    "\n",
    "# Example 1: Fixed length output\n",
    "vad_dataset_fixed = VADMixedDataset(\n",
    "    speech_datasets=speech_datasets,\n",
    "    noise_datasets=noise_datasets,\n",
    "    sample_rate=16000,\n",
    "    fixed_length=3.0,  # 3 seconds fixed length\n",
    "    target_speech_ratio=0.3\n",
    ")\n",
    "\n",
    "# Example 2: Random length output\n",
    "length_config = LengthConfig(min_length=2.0, max_length=5.0)  # Random between 2-5 seconds\n",
    "vad_dataset_random = VADMixedDataset(\n",
    "    speech_datasets=speech_datasets,\n",
    "    noise_datasets=noise_datasets,\n",
    "    sample_rate=16000,\n",
    "    length_config=length_config,\n",
    "    target_speech_ratio=0.3\n",
    ")\n",
    "\n",
    "# Get samples\n",
    "fixed_sample = vad_dataset_fixed[0]    # Will be exactly 3 seconds\n",
    "random_sample = vad_dataset_random[0]  # Will be between 2-5 seconds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
